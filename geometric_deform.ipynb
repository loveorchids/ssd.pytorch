{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import cv2, os, glob, re, torch, random, time\n",
    "import numpy as np\n",
    "import imgaug\n",
    "from imgaug import augmenters\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.ones(300, 300, 3).long() * 255\n",
    "prior = torch.tensor([[10, 10, 220, 280]]).float()\n",
    "reg = torch.tensor([[35, 45, 275, 225]]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_conv_point_vanilla(bboxes, kernel_size=3, c_min=0, c_max=1):\n",
    "    prior_centers = []\n",
    "    for bbox in bboxes:\n",
    "        c_x = bbox[2:] - bbox[:2]\n",
    "        x1, y1, x2, y2 = bbox.clamp(min=c_min, max=c_max)\n",
    "        # the gradient was not kept\n",
    "        step_x = float((x2 - x1) / kernel_size)\n",
    "        start_x = float(x1 + step_x / 2)\n",
    "        end_x = float(x2)\n",
    "        step_y = float((y2 - y1) / kernel_size)\n",
    "        start_y = float(y1 + step_y / 2)\n",
    "        end_y = float(y2)\n",
    "        prior_center = torch.meshgrid([torch.arange(start_x, end_x, step_x),\n",
    "                                       torch.arange(start_y, end_y, step_y)])\n",
    "        prior_center = torch.stack(prior_center, dim=-1).contiguous().view(-1)\n",
    "        prior_centers.append(prior_center)\n",
    "    return torch.stack(prior_centers, dim=0)   \n",
    "\n",
    "def center_conv_point_parallel(bboxes, kernel_size=3, c_min=0, c_max=1):\n",
    "    bboxes.clamp_(min=c_min, max=c_max)\n",
    "    base = torch.cat([bboxes[:, :2]] * (kernel_size ** 2), dim=1)\n",
    "    if bboxes.is_cuda:\n",
    "        multiplier = torch.tensor([(2 * i + 1) / kernel_size / 2 for i in range(kernel_size)]).cuda()\n",
    "    else:\n",
    "        multiplier = torch.tensor([(2 * i + 1) / kernel_size / 2 for i in range(kernel_size)])\n",
    "    multiplier = torch.stack(torch.meshgrid([multiplier, multiplier]), dim=-1).contiguous().view(-1)\n",
    "    multiplier = multiplier.unsqueeze(0).repeat(bboxes.size(0), 1)\n",
    "    center = torch.stack([bboxes[:, 2] - bboxes[:, 0], bboxes[:, 3] - bboxes[:, 1]], dim=-1)\n",
    "    center = torch.cat([center] * (kernel_size ** 2), dim=1)\n",
    "    return base + center * multiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQsAAAD8CAYAAABgtYFHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAEHpJREFUeJzt3W+MXNV9xvHvE2NIFVCBemu5/iMb4rZypMZYK9dVUESDEsBvDFKFzItgRZY2ao0EUirVJFJDpSKRqoCE1BIZYcVEFOMWEFbltnFcJJQXYNbUGP+pwwaM7NViL38CRJFIbX59MWfhspndObszd+7MnecjrebOmTs7v3N9/ey5956ZUURgZtbK56ouwMz6g8PCzLI4LMwsi8PCzLI4LMwsi8PCzLKUFhaSbpR0UtKYpO1lvY6ZdYfKmGchaQHwc+DrwBngJeC2iDje8Rczs64oa2SxHhiLiNcj4jfAbmBTSa9lZl1wUUm/dylwunD/DPCnM628aNGiWLlyZUmlmBnAoUOH3o6Iofk+v6ywaEnSCDACsGLFCkZHR6sqxWwgSHqzneeXdRgyDiwv3F+W2j4RETsiYjgihoeG5h12ZtYlZYXFS8BqSaskXQxsBvaW9Fpm1gWlHIZExHlJdwD/BSwAdkbEsTJey8y6o7RzFhGxD9hX1u83s+7yDE4zy1LZ1ZBsUtUV2CDwh0C15JGFmWXp/ZHFFCe/lcEj12weWZhZFoeFmWVxWJhZFoeFmWVxWJhZFoeFmWVxWJhZFoeFmWVxWJhZFoeFmWVxWJhZFoeFmWVxWJhZFoeFmWVxWJhZFoeFmWVxWJhZFoeFmWVxWJhZFoeFmWVxWJhZFoeFmWXpn68CaJM/8d2aS18x0eP7Ry98E0ZbYSHpFPAhcAE4HxHDkq4EngRWAqeAWyPivfbKNLOqdWJk8ecR8Xbh/nbgQETcJ2l7uv83HXidjuiFhLYeMjXk7NEdo5dGxGWcs9gE7ErLu4CbS3gNM+uydsMigJ9IOiRpJLUtjoiJtPwWsLjN1zCzHtDuYci1ETEu6feB/ZL+t/hgRISkpuO7FC4jACtWrGizjDZMH+f16HA0i/tiJWprZBER4+n2HPAMsB44K2kJQLo9N8Nzd0TEcEQMDw0NtVNGZ/XSQaJZD5l3WEj6gqTLppaBbwBHgb3AlrTaFuDZdossTfHkVr//5WrWl34Nvjr1pUbaOQxZDDyjxj/iRcC/RMR/SnoJ2CNpK/AmcGv7ZZpZ1eYdFhHxOvDlJu3vANe3U1TX1emvlvtiJRns6d79fujRSp36V6e+9KnBDotm+nWn7Ne6m6lTX2pkYN4bMqM67Zjui5XIIwszy+KwMLMsDgszy+KwMLMsDgszy+KwMLMsDgszy+J5FiUZlHdYN5uRXce+Dko/Z+ORRQma7Vh1fJtDHfvUzKD0sxWHRYnq8M73HO7nYHBYmFkWn7Mo0aAMX93PweCRRQmaDVXrOHx1PweLRxYlGZSdyf0cHB5ZmFkWh4WZZXFYmFkWh4WZZXFYmFkWh4WZZXFYmFkWh4WZZXFYmFkWh4WZZXFYmFmWlmEhaaekc5KOFtqulLRf0mvp9orULkkPSRqTdETSujKLN7PuyRlZ/Ai4cVrbduBARKwGDqT7ADcBq9PPCPBwZ8o0s6q1DIuIeB54d1rzJmBXWt4F3FxofywaXgAul7SkU8WaWXXme85icURMpOW3gMVpeSlwurDemdT2WySNSBqVNDo5OTnPMsysW9o+wRkRAcz53f4RsSMihiNieGhoqN0yzKxk8w2Ls1OHF+n2XGofB5YX1luW2sysz803LPYCW9LyFuDZQvvt6arIBuD9wuGKmfWxlh+rJ+kJ4DpgkaQzwPeB+4A9krYCbwK3ptX3ARuBMeDXwLdKqNnMKtAyLCLithkeur7JugFsa7coM+s9nsFpZlkcFmaWxWFhZlkcFmaWxWFhZlkcFmaWxWFhZlkcFmaWxWFhZlkcFmaWxWFhZlkcFmaWxWFhZlkcFmaWxWFhZlkcFmaWpeWH39j8SJ+9H3P+SOP+4H4ODo8srKOm/6eqq0HpZ5HDogRTO1LEp3+B6rhzNetnHQ1KP1txWJhZFoeFmWXxCc4SFQ896jx8reMhVlFEo49172crHlmUoM7BUNSsn4Pc97rzyKKka2KV7EwVXN8r7SV67FrlIIbDdB5ZTDfoY02zGQx2WNQpGJr1pV/7V6e+1Mhgh8WUOl1Ad1+sJC3DQtJOSeckHS203SNpXNLh9LOx8NjdksYknZR0Q1mFm1l35YwsfgTc2KT9wYhYm372AUhaA2wGvpSe88+SFnSq2NLU6bqY+2IlaRkWEfE88G7m79sE7I6IjyLiDWAMWN9GfeWq07U/98VK1s45izskHUmHKVektqXA6cI6Z1Lbb5E0ImlU0ujk5GQbZbRp6ri4DsfH7ouVaL5h8TBwNbAWmADun+sviIgdETEcEcNDQ0PzLMPMumVeYRERZyPiQkR8DDzCp4ca48DywqrLUpuZ9bl5hYWkJYW7twBTV0r2ApslXSJpFbAaONheiWbWC1pO95b0BHAdsEjSGeD7wHWS1gIBnAK+DRARxyTtAY4D54FtEXGhnNLNrJtahkVE3Nak+dFZ1r8XuLedosys93gGp5llcViYWRaHhZllcViYWRaHhZllcViYWRaHhZllcViYWRaHhZllcViYWRaHhZllcViYWRaHhZllcViYWRaHhZllcViYWRaHhZllcViYWRaHhZllcViYWRaHhZllcViYWRaHhZllcViYWZaWXzJk8yN99n5dvwjc/RwcHlmUYPqONVNbv3M/B4vDokQRg/EXyP0cDC3DQtJySc9JOi7pmKQ7U/uVkvZLei3dXpHaJekhSWOSjkhaV3YnzKx8OSOL88B3ImINsAHYJmkNsB04EBGrgQPpPsBNwOr0MwI83PGq+4Q0GMNV93MwtAyLiJiIiJfT8ofACWApsAnYlVbbBdycljcBj0XDC8DlkpZ0vPI+M8jD137nf7uGOV0NkbQSuAZ4EVgcERPpobeAxWl5KXC68LQzqW2CATEoO9eg9BMGq68zyT7BKelS4Cngroj4oPhYRAQwp80paUTSqKTRycnJuTzVzCqQFRaSFtIIiscj4unUfHbq8CLdnkvt48DywtOXpbbPiIgdETEcEcNDQ0Pzrd/MuiTnaoiAR4ETEfFA4aG9wJa0vAV4ttB+e7oqsgF4v3C4YmZ9KuecxVeAbwKvSjqc2r4L3AfskbQVeBO4NT22D9gIjAG/Br7V0YrNrBItwyIifgbMdMHo+ibrB7CtzbrMrMd4BqeZZXFYmFkWh4WZZXFYmFkWh4WZZXFYmFkWh4WZZXFYmFkWh4WZZXFYmFkWh4WZZXFYmFmWgfvekEH+DEVrJn1mk/eLljyyMLMsAzOy8GcoWlNTQ03vIC15ZGFmWRwWZpZlYA5DZlSnb7x1X6xEgz2yqNM33rovVrLBDospdfrGW/fFSuKwMLMsPmcB9Rriui9WksEeWdR9iFun/tWpL33KI4u67IR16QfUqy81MtgjCzPL5rAwsywOCzPLkvMt6sslPSfpuKRjku5M7fdIGpd0OP1sLDznbkljkk5KuqHMDphZd+Sc4DwPfCciXpZ0GXBI0v702IMR8Y/FlSWtATYDXwL+APippD+MiAudLNzMuqvlyCIiJiLi5bT8IXACWDrLUzYBuyPio4h4AxgD1neiWDOrzpzOWUhaCVwDvJia7pB0RNJOSVektqXA6cLTzjB7uJhZH8gOC0mXAk8Bd0XEB8DDwNXAWmACuH8uLyxpRNKopNHJycm5PNXMKpAVFpIW0giKxyPiaYCIOBsRFyLiY+ARPj3UGAeWF56+LLV9RkTsiIjhiBgeGhpqpw9m1gU5V0MEPAqciIgHCu1LCqvdAhxNy3uBzZIukbQKWA0c7FzJZlaFnKshXwG+Cbwq6XBq+y5wm6S1ND4e+RTwbYCIOCZpD3CcxpWUbb4SYtb/WoZFRPyM5h+Uvm+W59wL3NtGXWbWYzyD08yyOCzMLIvDwsyyOCzMLIvDwsyyOCzMLIvDwsyyOCzMLIvDwsyyOCzMLIvDwsyyOCzMLIvDwsyyOCzMLIvDwsyyOCzMLEv/fDGymn3+jpl1i0cWZpal90cWEVVXYGZ4ZGFmmRwWZpbFYWFmWRwWZpbFYWFmWRwWZpbFYWFmWRwWZpbFYWFmWVqGhaTPSzoo6RVJxyT9XWpfJelFSWOSnpR0cWq/JN0fS4+vLLcLZtYNOSOLj4CvRcSXgbXAjZI2AD8AHoyILwLvAVvT+luB91L7g2k9M+tzLcMiGn6V7i5MPwF8Dfi31L4LuDktb0r3SY9fL/kto2b9LuuNZJIWAIeALwL/BPwC+GVEnE+rnAGWpuWlwGmAiDgv6X3g94C3p/3OEWAk3f2VpHemr1OxRbie2fRaPdB7NfVaPX/UzpOzwiIiLgBrJV0OPAP8cTsvmn7nDmDH1H1JoxEx3O7v7RTXM7teqwd6r6ZerKed58/pakhE/BJ4Dvgz4HJJU2GzDBhPy+PA8lTcRcDvAu+0U6SZVS/nashQGlEg6XeArwMnaITGX6TVtgDPpuW96T7p8f+O8IdSmPW7nMOQJcCudN7ic8CeiPh3SceB3ZL+Hvgf4NG0/qPAjyWNAe8CmzNr2dF6la5yPbPrtXqg92qqVT3yH30zy+EZnGaWpfKwkHSjpJNpxuf2imo4JelVSYenzhhLulLSfkmvpdsrSq5hp6Rzko4W2prWoIaH0jY7Imldl+q5R9J42k6HJW0sPHZ3quekpBtKqGe5pOckHU8zie9M7ZVso1nqqWQbdWWmdURU9gMsoDFn4yrgYuAVYE0FdZwCFk1r+wdge1reDvyg5Bq+CqwDjraqAdgI/AcgYAPwYpfquQf46ybrrkn/dpcAq9K/6YIO17MEWJeWLwN+nl63km00Sz2VbKPUz0vT8kLgxdTvPcDm1P5D4C/T8l8BP0zLm4EnW71G1SOL9cBYRLweEb8BdtOYAdoLijNRizNUSxERz9M4IZxTwybgsWh4gcZl7CVdqGcmm4DdEfFRRLwBjNH4t+1kPRMR8XJa/pDGFbmlVLSNZqlnJqVuo9TPUmdaVx0Wn8z2TIozQbspgJ9IOpRmlgIsjoiJtPwWsLiCumaqocrtdkca1u8sHJp1tZ40ZL6Gxl/PyrfRtHqgom0kaYGkw8A5YD9zmGkNTM20nlHVYdErro2IdcBNwDZJXy0+GI2xWqWXjXqhBuBh4GoabyicAO7vdgGSLgWeAu6KiA+Kj1WxjZrUU9k2iogLEbGWxiTJ9XRgpnVR1WHxyWzPpDgTtGsiYjzdnqMxnX09cHZq2Jpuz3W7rllqqGS7RcTZtEN+DDzCp8PortQjaSGN/5iPR8TTqbmybdSsnqq3UaqhlJnWVYfFS8DqdMb2YhonWvZ2swBJX5B02dQy8A3gKJ+diVqcodpNM9WwF7g9nfHfALxfGIqXZtox/y00ttNUPZvTGfZVwGrgYIdfWzQm/J2IiAcKD1WyjWaqp6ptpG7MtO7kGeJ5nsXdSONM8i+A71Xw+lfROEv9CnBsqgYax28HgNeAnwJXllzHEzSGrf9H49hy60w10DjzPfXu31eB4S7V8+P0ekfSzraksP73Uj0ngZtKqOdaGocYR4DD6WdjVdtolnoq2UbAn9CYSX2ERkD9bWH/PkjjhOq/Apek9s+n+2Pp8atavYZncJpZlqoPQ8ysTzgszCyLw8LMsjgszCyLw8LMsjgszCyLw8LMsjgszCzL/wMKDcl0gHIs5gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_box(image, prior_box, reg_box):\n",
    "    image = image.data.numpy().astype(\"uint8\").copy()\n",
    "    \n",
    "    # get prior box and its inter conv points\n",
    "    prior_conv_center = center_conv_point_parallel(prior_box, c_max=300)\n",
    "    # Draw conv center\n",
    "    for coord in prior_conv_center.view(-1, 2):\n",
    "        cv2.circle(image, (int(coord[0]), int(coord[1])), 3, (255, 0, 0), 2)\n",
    "    prior_box = prior_box.long().data.numpy()\n",
    "    \n",
    "    # get regressed box and its regress conv points\n",
    "    reg_conv_center = center_conv_point_parallel(reg_box, c_max=300)\n",
    "    for coord in reg_conv_center.view(-1, 2):\n",
    "        cv2.circle(image, (int(coord[0]), int(coord[1])), 3, (0, 0, 255), 2)\n",
    "    reg_box = reg_box.long().data.numpy()\n",
    "    \n",
    "    # Draw the box out\n",
    "    x1, y1, x2, y2 = prior_box[0]\n",
    "    cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "    x1, y1, x2, y2 = reg_box[0]\n",
    "    cv2.rectangle(image, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "    plt.imshow(image)\n",
    "    return prior_conv_center, reg_conv_center\n",
    "prior_conv_center, reg_conv_center = plot_box(img, prior, reg)\n",
    "deformation_map = reg_conv_center - prior_conv_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth:\n",
      "tensor([[0.5330, 0.0167, 0.5330,  ..., 0.0500, 0.6648, 0.0833],\n",
      "        [0.4636, 0.0717, 0.4636,  ..., 0.2152, 0.7969, 0.3587],\n",
      "        [0.5833, 0.4079, 0.5833,  ..., 0.5252, 0.9167, 0.6426],\n",
      "        ...,\n",
      "        [0.0224, 0.3457, 0.0224,  ..., 0.5123, 0.1119, 0.6790],\n",
      "        [0.0167, 0.0167, 0.0167,  ..., 0.0500, 0.0833, 0.0833],\n",
      "        [0.0657, 0.0833, 0.0657,  ..., 0.2500, 0.3287, 0.4167]])\n",
      "\n",
      "Parallel:\n",
      "tensor([[0.5330, 0.0167, 0.5330,  ..., 0.0500, 0.6648, 0.0833],\n",
      "        [0.4636, 0.0717, 0.4636,  ..., 0.2152, 0.7969, 0.3587],\n",
      "        [0.5833, 0.4079, 0.5833,  ..., 0.5252, 0.9167, 0.6426],\n",
      "        ...,\n",
      "        [0.0224, 0.3457, 0.0224,  ..., 0.5123, 0.1119, 0.6790],\n",
      "        [0.0167, 0.0167, 0.0167,  ..., 0.0500, 0.0833, 0.0833],\n",
      "        [0.0657, 0.0833, 0.0657,  ..., 0.2500, 0.3287, 0.4167]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-3.7998e-06, device='cuda:0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_size = 3\n",
    "n_sample = 1024\n",
    "base = torch.randn(n_sample, 2).clamp(min=0, max=0.5)\n",
    "bboxes = torch.cat([base, base + torch.randn(n_sample, 2).clamp(min=0.1, max=0.5)], dim=1).contiguous().cuda()\n",
    "print(\"Ground truth:\")\n",
    "print(center_conv_point_vanilla(bboxes))\n",
    "print(\"\")\n",
    "print(\"Parallel:\")\n",
    "print(center_conv_point_parallel(bboxes))\n",
    "\n",
    "torch.sum(center_conv_point_parallel(bboxes) - center_conv_point_vanilla(bboxes).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0278, 0.0278, 0.0278, 0.0566, 0.0278, 0.0856, 0.0566, 0.0278, 0.0566,\n",
       "         0.0566, 0.0566, 0.0856, 0.0856, 0.0278, 0.0856, 0.0566, 0.0856, 0.0856]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = torch.tensor([[0.0133, 0.0133, 0.1000, 0.1000]])\n",
    "center_conv_point_parallel(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_prior_idx = torch.tensor([3, 3, 0, 1, 7, 7])\n",
    "best_truth_idx = torch.tensor([2, 3, 1, 0, 3, 4, 0, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3, 1, 1, 3, 4, 0, 5])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_truth_idx[best_prior_idx] = torch.arange(best_prior_idx.size(0))\n",
    "best_truth_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3, 1, 1, 3, 4, 0, 5])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for j in range(best_prior_idx.size(0)):\n",
    "    best_truth_idx[best_prior_idx[j]] = j\n",
    "best_truth_idx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
